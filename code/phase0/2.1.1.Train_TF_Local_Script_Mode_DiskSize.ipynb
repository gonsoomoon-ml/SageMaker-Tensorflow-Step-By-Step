{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.1] 세이지 메이커 로컬 모드 및 스크립트 모드로 훈련\n",
    "\n",
    "본 워크샵의 모든 노트북은 **<font color=\"red\">conda_tensorflow2_p36</font>** 를 사용합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 1. 기본 환경 세팅 \n",
    "- 2. 노트북에서 세이지 메이커 스크립트 모드 스타일로 코드 변경\n",
    "- 3. 세이지 메이커 로컬 모드로 훈련\n",
    "- 4. 세이지 메이커의 호스트 모드로 훈련\n",
    "- 5. 모델 아티펙트 경로 저장\n",
    "\n",
    "\n",
    "- 이 노트북은 아래와 같이 훈련 잡이 실행되는 \"관리형 EC2 인스턴스\" 의 저장 공간을 확인할 수 있는 \"함수\"를 훈련 스크립트에 추가했습니다.\n",
    "    - 훈련시에 아래와 같은 저장 정보를 얻을 수 있습니다.\n",
    "    - 자세한 내용은 이 훈련 코드를 참조 하세요. --> src/cifar10_tf2_sm_disk_size.py\n",
    "\n",
    "![file-system-usage.png](images/file-system-usage.png)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기본 환경 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_dir\n",
    "%store -r validation_dir\n",
    "%store -r eval_dir\n",
    "%store -r data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 노트북에서 세이지 메이커 스크립트 모드 스타일로 코드 변경\n",
    "\n",
    "- Keras 버전의 스크래치 코드에서 세이지 메이커의 코드 변경을 참고 하세요.\n",
    "    - `1.2.Train_Keras_Local_Script_Mode.ipynb` 참고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize src/cifar10_tf2_sm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 세이지 메이커 로컬 모드로 훈련\n",
    "\n",
    "본격적으로 학습을 시작하기 전에 로컬 모드를 사용하여 디버깅을 먼저 수행합니다. 로컬 모드는 학습 인스턴스를 생성하는 과정이 없이 로컬 인스턴스로 컨테이너를 가져온 후 곧바로 학습을 수행하기 때문에 코드를 보다 신속히 검증할 수 있습니다.\n",
    "\n",
    "Amazon SageMaker Python SDK의 로컬 모드는 TensorFlow 또는 MXNet estimator서 단일 인자값을 변경하여 CPU (단일 및 다중 인스턴스) 및 GPU (단일 인스턴스) SageMaker 학습 작업을 에뮬레이션(enumlate)할 수 있습니다. \n",
    "\n",
    "로컬 모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 아래 코드 셀을 통해 본 노트북 환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. \n",
    " \n",
    "로컬 모드의 학습을 통해 여러분의 코드가 현재 사용 중인 하드웨어를 적절히 활용하고 있는지 확인하기 위한 GPU 점유와 같은 지표(metric)를 쉽게 모니터링할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬 모드로 훈련 실행\n",
    "- 아래의 두 라인이 로컬모드로 훈련을 지시 합니다.\n",
    "```python\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "instance_type = \"local_gpu\" # GPU 사용을 가정 합니다. CPU 사용시에 'local' 로 정의 합니다.\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 작업을 시작하기 위해 `estimator.fit() ` 호출 시, Amazon ECS에서 Amazon SageMaker TensorFlow 컨테이너를 로컬 노트북 인스턴스로 다운로드합니다.\n",
    "\n",
    "`sagemaker.tensorflow` 클래스를 사용하여 SageMaker Python SDK의 Tensorflow Estimator 인스턴스를 생성합니다.\n",
    "인자값으로 하이퍼파라메터와 다양한 설정들을 변경할 수 있습니다.\n",
    "\n",
    "\n",
    "자세한 내용은 [documentation](https://sagemaker.readthedocs.io/en/stable/using_tf.html#training-with-tensorflow-estimator)을 확인하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "                    'epochs' : 1,\n",
    "                    'learning-rate' : 0.001,\n",
    "                    'print-interval' : 100,\n",
    "                    'train-batch-size': 256,    \n",
    "                    'eval-batch-size': 512,        \n",
    "                    'validation-batch-size': 512,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_tf2_sm_disk_size.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       framework_version='2.4.1',\n",
    "                       py_version='py37',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters= hyperparameters,\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type= instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0rne89x5ps-algo-1-3ne7i ... \n",
      "Creating 0rne89x5ps-algo-1-3ne7i ... done\n",
      "Attaching to 0rne89x5ps-algo-1-3ne7i\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:43.352032: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:43.352186: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:43.356455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:43.393397: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:45,218 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:45,768 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Training Env:\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"eval\": \"/opt/ml/input/data/eval\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"current_host\": \"algo-1-3ne7i\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"algo-1-3ne7i\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     ],\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"learning-rate\": 0.001,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"print-interval\": 100,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"train-batch-size\": 256,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"eval-batch-size\": 512,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"validation-batch-size\": 512,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"train\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"validation\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"eval\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         }\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"job_name\": \"cifar10-2021-12-08-08-52-40-254\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"master_hostname\": \"algo-1-3ne7i\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/source/sourcedir.tar.gz\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"module_name\": \"cifar10_tf2_sm_disk_size\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"current_host\": \"algo-1-3ne7i\",\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m             \"algo-1-3ne7i\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m         ]\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     },\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m     \"user_entry_point\": \"cifar10_tf2_sm_disk_size.py\"\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m }\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Environment variables:\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HOSTS=[\"algo-1-3ne7i\"]\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HPS={\"epochs\":1,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512}\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_USER_ENTRY_POINT=cifar10_tf2_sm_disk_size.py\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-3ne7i\",\"hosts\":[\"algo-1-3ne7i\"]}\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_INPUT_DATA_CONFIG={\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_CHANNELS=[\"eval\",\"train\",\"validation\"]\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_CURRENT_HOST=algo-1-3ne7i\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_MODULE_NAME=cifar10_tf2_sm_disk_size\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/source/sourcedir.tar.gz\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-3ne7i\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-3ne7i\"],\"hyperparameters\":{\"epochs\":1,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-2021-12-08-08-52-40-254\",\"log_level\":20,\"master_hostname\":\"algo-1-3ne7i\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_tf2_sm_disk_size\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-3ne7i\",\"hosts\":[\"algo-1-3ne7i\"]},\"user_entry_point\":\"cifar10_tf2_sm_disk_size.py\"}\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--eval-batch-size\",\"512\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model\",\"--print-interval\",\"100\",\"--train-batch-size\",\"256\",\"--validation-batch-size\",\"512\"]\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_CHANNEL_EVAL=/opt/ml/input/data/eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_LEARNING-RATE=0.001\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_PRINT-INTERVAL=100\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_TRAIN-BATCH-SIZE=256\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_EVAL-BATCH-SIZE=512\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_VALIDATION-BATCH-SIZE=512\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /usr/local/bin/python3.7 cifar10_tf2_sm_disk_size.py --epochs 1 --eval-batch-size 512 --learning-rate 0.001 --model_dir s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model --print-interval 100 --train-batch-size 256 --validation-batch-size 512\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tensorflow version:  2.4.1\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Disk Size: Filesystem      Size  Used Avail Use% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m overlay         109G  100G  8.7G  93% /\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs            64M     0   64M   0% /dev\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /sys/fs/cgroup\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m shm              64M     0   64M   0% /dev/shm\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1      109G  100G  8.7G  93% /etc/hosts\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvdf       984G   25G  909G   3% /opt/ml/input/data/eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G   12K  241G   1% /proc/driver/nvidia\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m devtmpfs        241G   76K  241G   1% /dev/nvidia0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /proc/acpi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /proc/scsi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /sys/firmware\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Disk Size (inode) :  Filesystem     Inodes IUsed IFree IUse% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m overlay          6.9M  2.4M  4.5M   35% /\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    28   61M    1% /dev\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    11   61M    1% /sys/fs/cgroup\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m shm               61M     1   61M    1% /dev/shm\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1       6.9M  2.4M  4.5M   35% /etc/hosts\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvdf         63M  285K   63M    1% /opt/ml/input/data/eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    13   61M    1% /proc/driver/nvidia\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m devtmpfs          61M   908   61M    1% /dev/nvidia0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /proc/acpi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /proc/scsi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /sys/firmware\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /opt/ml/checkpoints :  \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /opt/ml/model :  Filesystem      Size  Used Avail Use% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1      109G  100G  8.7G  93% /opt/ml/model\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m args: \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m  Namespace(epochs=1, eval='/opt/ml/input/data/eval', eval_batch_size=512, learning_rate=0.001, model_dir='s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-52-40-254/model', model_output_dir='/opt/ml/model', momentum=0.9, optimizer='adam', print_interval=100, train='/opt/ml/input/data/train', train_batch_size=256, validation='/opt/ml/input/data/validation', validation_batch_size=512, weight_decay=0.0002)\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Channel Name: train\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m buffer_size:  10000\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches in train:  39\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Channel Name: eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches in eval:  19\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Channel Name: validation\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m # of batches in validation:  19\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m [2021-12-08 08:53:00.313 58d7bf1873fa:149 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m [2021-12-08 08:53:00.348 58d7bf1873fa:149 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Step #0\tLoss: 109.933960\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Epoch 1, Test Loss: 2.3061389923095703, Test Accuracy: 11.091693878173828\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Training Finished.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Disk Size: Filesystem      Size  Used Avail Use% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m overlay         109G  100G  8.7G  93% /\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs            64M     0   64M   0% /dev\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /sys/fs/cgroup\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m shm              64M     0   64M   0% /dev/shm\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1      109G  100G  8.7G  93% /etc/hosts\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvdf       984G   25G  909G   3% /opt/ml/input/data/eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G   12K  241G   1% /proc/driver/nvidia\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m devtmpfs        241G   76K  241G   1% /dev/nvidia0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /proc/acpi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /proc/scsi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs           241G     0  241G   0% /sys/firmware\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m Disk Size (inode) :  Filesystem     Inodes IUsed IFree IUse% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m overlay          6.9M  2.4M  4.5M   35% /\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    28   61M    1% /dev\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    11   61M    1% /sys/fs/cgroup\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m shm               61M     1   61M    1% /dev/shm\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1       6.9M  2.4M  4.5M   35% /etc/hosts\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvdf         63M  285K   63M    1% /opt/ml/input/data/eval\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M    13   61M    1% /proc/driver/nvidia\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m devtmpfs          61M   908   61M    1% /dev/nvidia0\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /proc/acpi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /proc/scsi\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m tmpfs             61M     1   61M    1% /sys/firmware\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /opt/ml/checkpoints :  \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /opt/ml/model :  Filesystem      Size  Used Avail Use% Mounted on\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m /dev/xvda1      109G  100G  8.7G  93% /opt/ml/model\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:45.924490: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:45.924652: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:52:45.966600: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m df: /opt/ml/checkpoints: No such file or directory\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:53:04.552777: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m df: /opt/ml/checkpoints: No such file or directory\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m \n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i |\u001b[0m 2021-12-08 08:53:07,533 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36m0rne89x5ps-algo-1-3ne7i exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "CPU times: user 615 ms, sys: 76.9 ms, total: 692 ms\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator.fit({'train': f'file://{train_dir}',\n",
    "               'validation': f'file://{validation_dir}',\n",
    "               'eval': f'file://{eval_dir}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 세이지 메이커의 호스트 모드로 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/data/DEMO-cifar10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path=data_dir, key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "                    'epochs' : 20,\n",
    "                    'learning-rate' : 0.001,    \n",
    "                    'print-interval' : 100,\n",
    "                    'train-batch-size': 256,    \n",
    "                    'eval-batch-size': 512,        \n",
    "                    'validation-batch-size': 512,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "instance_type='ml.p3.8xlarge'\n",
    "\n",
    "sm_estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_tf2_sm_disk_size.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       framework_version='2.4.1',\n",
    "                       py_version='py37',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters= hyperparameters,\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type= instance_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Host Mode 로 훈련\n",
    "- `cifar10_estimator.fit(inputs, wait=False)`\n",
    "    - 입력 데이터를 inputs로서 S3 의 경로를 제공합니다.\n",
    "    - wait=False 로 지정해서 async 모드로 훈련을 실행합니다. \n",
    "        - 실행 경과는 아래의 cifar10_estimator.logs() 에서 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 ms, sys: 0 ns, total: 159 ms\n",
      "Wall time: 532 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-08 08:55:33 Starting - Starting the training job...\n",
      "2021-12-08 08:55:56 Starting - Launching requested ML instancesProfilerReport-1638953732: InProgress\n",
      ".........\n",
      "2021-12-08 08:57:28 Starting - Preparing the instances for training......\n",
      "2021-12-08 08:58:18 Downloading - Downloading input data...\n",
      "2021-12-08 08:58:56 Training - Downloading the training image.................\u001b[34m2021-12-08 09:01:41.518525: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:41.522731: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:41.604479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:41.696620: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:45,191 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:45,771 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"validation-batch-size\": 512,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"print-interval\": 100,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model\",\n",
      "        \"train-batch-size\": 256,\n",
      "        \"epochs\": 20,\n",
      "        \"eval-batch-size\": 512\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-2021-12-08-08-55-32-455\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_tf2_sm_disk_size\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_tf2_sm_disk_size.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10_tf2_sm_disk_size.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10_tf2_sm_disk_size\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-2021-12-08-08-55-32-455\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_tf2_sm_disk_size\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_tf2_sm_disk_size.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--eval-batch-size\",\"512\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model\",\"--print-interval\",\"100\",\"--train-batch-size\",\"256\",\"--validation-batch-size\",\"512\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION-BATCH-SIZE=512\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_PRINT-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL-BATCH-SIZE=512\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 cifar10_tf2_sm_disk_size.py --epochs 20 --eval-batch-size 512 --learning-rate 0.001 --model_dir s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model --print-interval 100 --train-batch-size 256 --validation-batch-size 512\u001b[0m\n",
      "\u001b[34mtensorflow version:  2.4.1\u001b[0m\n",
      "\u001b[34mDisk Size: Filesystem                                                                                        Size  Used Avail Use% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/docker-202:1-394444-06d92dd3751ee66b2dbf2841609f224fe47cfbd79f7bd60b991933abc123eda3   26G  8.5G   16G  35% /\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                              64M     0   64M   0% /dev\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /sys/fs/cgroup\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt                                                                             30G  134M   28G   1% /tmp\u001b[0m\n",
      "\u001b[34m/dev/xvda1                                                                                         40G  8.9G   31G  23% /etc/hosts\u001b[0m\n",
      "\u001b[34mshm                                                                                               119G     0  119G   0% /dev/shm\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G   12K  121G   1% /proc/driver/nvidia\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G  4.0K  121G   1% /etc/nvidia/nvidia-application-profiles-rc.d\u001b[0m\n",
      "\u001b[34mdevtmpfs                                                                                          121G  144K  121G   1% /dev/nvidia0\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /proc/acpi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /proc/scsi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /sys/firmware\u001b[0m\n",
      "\u001b[34mDisk Size (inode) :  Filesystem                                                                                       Inodes IUsed IFree IUse% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/docker-202:1-394444-06d92dd3751ee66b2dbf2841609f224fe47cfbd79f7bd60b991933abc123eda3   1.7M  106K  1.6M    7% /\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M    23   31M    1% /dev\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M    11   31M    1% /sys/fs/cgroup\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt                                                                             1.9M    54  1.9M    1% /tmp\u001b[0m\n",
      "\u001b[34m/dev/xvda1                                                                                         2.5M   86K  2.5M    4% /etc/hosts\u001b[0m\n",
      "\u001b[34mshm                                                                                                 31M     1   31M    1% /dev/shm\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     9   31M    1% /proc/driver/nvidia\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     2   31M    1% /etc/nvidia/nvidia-application-profiles-rc.d\u001b[0m\n",
      "\u001b[34mdevtmpfs                                                                                            31M   911   31M    1% /dev/nvidia0\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /proc/acpi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /proc/scsi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /sys/firmware\u001b[0m\n",
      "\u001b[34m/opt/ml/checkpoints :  \u001b[0m\n",
      "\u001b[34m/opt/ml/model :  Filesystem              Size  Used Avail Use% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt   30G  134M   28G   1% /opt/ml/model\u001b[0m\n",
      "\u001b[34margs: \n",
      " Namespace(epochs=20, eval='/opt/ml/input/data/eval', eval_batch_size=512, learning_rate=0.001, model_dir='s3://sagemaker-us-east-1-057716757052/cifar10-2021-12-08-08-55-32-455/model', model_output_dir='/opt/ml/model', momentum=0.9, optimizer='adam', print_interval=100, train='/opt/ml/input/data/train', train_batch_size=256, validation='/opt/ml/input/data/validation', validation_batch_size=512, weight_decay=0.0002)\u001b[0m\n",
      "\u001b[34mChannel Name: train\u001b[0m\n",
      "\n",
      "2021-12-08 09:01:57 Training - Training image download completed. Training in progress.\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34mbuffer_size:  10000\u001b[0m\n",
      "\u001b[34m# of batches in train:  39\u001b[0m\n",
      "\u001b[34mChannel Name: eval\u001b[0m\n",
      "\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34m# of batches in eval:  19\u001b[0m\n",
      "\u001b[34mChannel Name: validation\u001b[0m\n",
      "\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34m# of batches in validation:  19\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.679 ip-10-0-217-161.ec2.internal:83 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.771 ip-10-0-217-161.ec2.internal:83 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.772 ip-10-0-217-161.ec2.internal:83 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.773 ip-10-0-217-161.ec2.internal:83 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.773 ip-10-0-217-161.ec2.internal:83 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.773 ip-10-0-217-161.ec2.internal:83 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-12-08 09:01:58.774 ip-10-0-217-161.ec2.internal:83 INFO hook.py:413] Monitoring the collections: losses, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 59.579128\u001b[0m\n",
      "\u001b[34mEpoch 1, Test Loss: 2.195589542388916, Test Accuracy: 18.1640625\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 2.205712\u001b[0m\n",
      "\u001b[34mEpoch 2, Test Loss: 1.94818115234375, Test Accuracy: 28.4642276763916\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.988932\u001b[0m\n",
      "\u001b[34mEpoch 3, Test Loss: 1.8580478429794312, Test Accuracy: 32.60690689086914\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.879843\u001b[0m\n",
      "\u001b[34mEpoch 4, Test Loss: 1.8678134679794312, Test Accuracy: 32.31907653808594\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.790190\u001b[0m\n",
      "\u001b[34mEpoch 5, Test Loss: 1.7230304479599, Test Accuracy: 36.78042984008789\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.746572\u001b[0m\n",
      "\u001b[34mEpoch 6, Test Loss: 1.7065407037734985, Test Accuracy: 36.986019134521484\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.812850\u001b[0m\n",
      "\u001b[34mEpoch 7, Test Loss: 1.677924633026123, Test Accuracy: 38.558799743652344\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.569944\u001b[0m\n",
      "\u001b[34mEpoch 8, Test Loss: 1.656528115272522, Test Accuracy: 40.17269515991211\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.595661\u001b[0m\n",
      "\u001b[34mEpoch 9, Test Loss: 1.6048216819763184, Test Accuracy: 40.501644134521484\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.663032\u001b[0m\n",
      "\u001b[34mEpoch 10, Test Loss: 1.6305524110794067, Test Accuracy: 39.81291198730469\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.626890\u001b[0m\n",
      "\u001b[34mEpoch 11, Test Loss: 1.5828536748886108, Test Accuracy: 41.81743621826172\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.596978\u001b[0m\n",
      "\u001b[34mEpoch 12, Test Loss: 1.562485694885254, Test Accuracy: 42.94818878173828\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.539608\u001b[0m\n",
      "\u001b[34mEpoch 13, Test Loss: 1.5602960586547852, Test Accuracy: 42.917354583740234\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.422173\u001b[0m\n",
      "\u001b[34mEpoch 14, Test Loss: 1.5570544004440308, Test Accuracy: 43.45188903808594\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.484133\u001b[0m\n",
      "\u001b[34mEpoch 15, Test Loss: 1.5443063974380493, Test Accuracy: 44.068668365478516\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.637445\u001b[0m\n",
      "\u001b[34mEpoch 16, Test Loss: 1.5573339462280273, Test Accuracy: 43.75\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.494861\u001b[0m\n",
      "\n",
      "2021-12-08 09:02:33 Uploading - Uploading generated training model\u001b[34mEpoch 17, Test Loss: 1.5343754291534424, Test Accuracy: 45.01438903808594\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.560141\u001b[0m\n",
      "\u001b[34mEpoch 18, Test Loss: 1.5677881240844727, Test Accuracy: 43.863075256347656\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.502212\u001b[0m\n",
      "\u001b[34mEpoch 19, Test Loss: 1.5218335390090942, Test Accuracy: 45.32278060913086\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.447095\u001b[0m\n",
      "\u001b[34mEpoch 20, Test Loss: 1.511285662651062, Test Accuracy: 45.44613265991211\u001b[0m\n",
      "\u001b[34mTraining Finished.\u001b[0m\n",
      "\u001b[34mDisk Size: Filesystem                                                                                        Size  Used Avail Use% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/docker-202:1-394444-06d92dd3751ee66b2dbf2841609f224fe47cfbd79f7bd60b991933abc123eda3   26G  8.5G   16G  35% /\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                              64M     0   64M   0% /dev\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /sys/fs/cgroup\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt                                                                             30G  141M   28G   1% /tmp\u001b[0m\n",
      "\u001b[34m/dev/xvda1                                                                                         40G  8.9G   31G  23% /etc/hosts\u001b[0m\n",
      "\u001b[34mshm                                                                                               119G     0  119G   0% /dev/shm\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G   12K  121G   1% /proc/driver/nvidia\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G  4.0K  121G   1% /etc/nvidia/nvidia-application-profiles-rc.d\u001b[0m\n",
      "\u001b[34mdevtmpfs                                                                                          121G  144K  121G   1% /dev/nvidia0\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /proc/acpi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /proc/scsi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                             121G     0  121G   0% /sys/firmware\u001b[0m\n",
      "\u001b[34mDisk Size (inode) :  Filesystem                                                                                       Inodes IUsed IFree IUse% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/docker-202:1-394444-06d92dd3751ee66b2dbf2841609f224fe47cfbd79f7bd60b991933abc123eda3   1.7M  106K  1.6M    7% /\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M    23   31M    1% /dev\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M    11   31M    1% /sys/fs/cgroup\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt                                                                             1.9M    67  1.9M    1% /tmp\u001b[0m\n",
      "\u001b[34m/dev/xvda1                                                                                         2.5M   86K  2.5M    4% /etc/hosts\u001b[0m\n",
      "\u001b[34mshm                                                                                                 31M     1   31M    1% /dev/shm\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     9   31M    1% /proc/driver/nvidia\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     2   31M    1% /etc/nvidia/nvidia-application-profiles-rc.d\u001b[0m\n",
      "\u001b[34mdevtmpfs                                                                                            31M   911   31M    1% /dev/nvidia0\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /proc/acpi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /proc/scsi\u001b[0m\n",
      "\u001b[34mtmpfs                                                                                               31M     1   31M    1% /sys/firmware\u001b[0m\n",
      "\u001b[34m/opt/ml/checkpoints :  \u001b[0m\n",
      "\u001b[34m/opt/ml/model :  Filesystem              Size  Used Avail Use% Mounted on\u001b[0m\n",
      "\u001b[34m/dev/mapper/xvdf_crypt   30G  141M   28G   1% /opt/ml/model\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:45.918277: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:45.918423: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-12-08 09:01:45.959195: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mdf: /opt/ml/checkpoints: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-12-08 09:02:26.558763: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mdf: /opt/ml/checkpoints: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-12-08 09:02:29,250 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-12-08 09:02:58 Completed - Training job completed\n",
      "ProfilerReport-1638953732: NoIssuesFound\n",
      "Training seconds: 262\n",
      "Billable seconds: 262\n"
     ]
    }
   ],
   "source": [
    "sm_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 아티펙트 저장\n",
    "- S3 에 저장된 모델 아티펙트를 저장하여 추론시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_tf_artifact_path:  s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/output/model.tar.gz\n",
      "Stored 'tf2_script_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "tf2_script_artifact_path = sm_estimator.model_data\n",
    "print(\"script_tf_artifact_path: \", tf2_script_artifact_path)\n",
    "\n",
    "%store tf2_script_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
