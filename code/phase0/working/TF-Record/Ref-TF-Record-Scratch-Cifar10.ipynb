{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321ff342",
   "metadata": {},
   "source": [
    "# [python/Tensorflow] TFRecord를 만들어서 최소한의 CIFAR-10데이터로 학습시키기\n",
    "- https://engineer-mole.tistory.com/212\n",
    "\n",
    "### 참고\n",
    "\n",
    "- 텐서플로우 Dataset: repeat(), batch(), take()\n",
    "    - https://deep-deep-deep.tistory.com/27\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fdb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfd41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[4], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eddd40",
   "metadata": {},
   "source": [
    "# 3. NumPy 배열의 TFRecord화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46514af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "y_train shape:  (50000, 1)\n",
      "X_test shape:  (10000, 32, 32, 3)\n",
      "y_test shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "\n",
    "def _bytes_feature(value): \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value])) \n",
    "def serialize_sample(image, label): \n",
    "    image_binary = (image.astype(np.float32) / 255.0).tobytes() \n",
    "    label_binary = np.eye(10).astype(np.float32)[label].tobytes() \n",
    "    image_list = _bytes_feature(image_binary) \n",
    "    label_list = _bytes_feature(label_binary) \n",
    "    proto = tf.train.Example(features=tf.train.Features(feature={ \"image\": image_list, # float32, (32, 32, 3) \n",
    "                                                                 \"label\": label_list # float32, (10, ) \n",
    "                                                                })) \n",
    "    return proto.SerializeToString() \n",
    "\n",
    "def write_record(): \n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data() \n",
    "    \n",
    "    print(\"X_train shape: \", X_train.shape)\n",
    "    print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "    print(\"X_test shape: \", X_test.shape)\n",
    "    print(\"y_test shape: \", y_test.shape)\n",
    "    \n",
    "    \n",
    "    with tf.io.TFRecordWriter(\"train.tfrecord\") as writer: \n",
    "        for i in range(X_train.shape[0]): \n",
    "            example = serialize_sample(X_train[i], y_train[i]) \n",
    "            writer.write(example) \n",
    "    with tf.io.TFRecordWriter(\"test.tfrecord\") as writer: \n",
    "        for i in range(X_test.shape[0]): \n",
    "            example = serialize_sample(X_test[i], y_test[i]) \n",
    "            writer.write(example) \n",
    "                    \n",
    "if __name__ == \"__main__\": \n",
    "    write_record()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc822403",
   "metadata": {},
   "source": [
    "# 4. 만든 TFRecord를 읽어들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a31c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of batches loading TFRecord : -2\n",
      "# of batches loading TFRecord : 50000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers \n",
    "import numpy as np \n",
    "\n",
    "def deserialize_example(serialized_string): \n",
    "    image_feature_description = { 'image': tf.io.FixedLenFeature([], tf.string), \n",
    "                                 'label': tf.io.FixedLenFeature([], tf.string), } \n",
    "    example = tf.io.parse_single_example(serialized_string, image_feature_description) \n",
    "    image = tf.reshape(tf.io.decode_raw(example[\"image\"], tf.float32), (32, 32, 3)) \n",
    "    label = tf.io.decode_raw(example[\"label\"], tf.float32) \n",
    "    return image, label \n",
    "\n",
    "def read_record(): \n",
    "    dataset = tf.data.TFRecordDataset(\"train.tfrecord\").map(deserialize_example).batch(1) \n",
    "    for x in dataset: \n",
    "        print(x) \n",
    "        break \n",
    "\n",
    "def read_record2(): \n",
    "#     dataset = tf.data.TFRecordDataset(\"train.tfrecord\").map(deserialize_example).batch(1) \n",
    "    dataset = tf.data.TFRecordDataset(\"train.tfrecord\").map(deserialize_example)    \n",
    "    ds_size = sum(1 for _ in dataset)    \n",
    "    print(\"# of batches loading TFRecord : {0}\".format(tf.data.experimental.cardinality(dataset).numpy()))    \n",
    "    print(\"# of batches loading TFRecord : {0}\".format(ds_size)) \n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\": \n",
    "    read_record2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970ac8b",
   "metadata": {},
   "source": [
    "# 5. TFRecord로 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ca8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n",
      "[2021-10-02 14:26:29.127 ip-172-16-67-78:105296 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-10-02 14:26:29.532 ip-172-16-67-78:105296 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Train for 390 steps\n",
      "Epoch 1/3\n",
      "390/390 [==============================] - 12s 30ms/step - loss: 1.2954 - accuracy: 0.5295 - val_loss: 2.0364 - val_accuracy: 0.3797\n",
      "Epoch 2/3\n",
      "390/390 [==============================] - 8s 20ms/step - loss: 0.8036 - accuracy: 0.7151 - val_loss: 1.2064 - val_accuracy: 0.6024\n",
      "Epoch 3/3\n",
      "390/390 [==============================] - 8s 20ms/step - loss: 0.6140 - accuracy: 0.7872 - val_loss: 1.0648 - val_accuracy: 0.6521\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import tensorflow.keras.layers as layers \n",
    "import numpy as np \n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU') \n",
    "# if gpus: \n",
    "#     try: # Currently, memory growth needs to be the same across GPUs \n",
    "#         for gpu in gpus: \n",
    "#             tf.config.experimental.set_memory_growth(gpu, True) \n",
    "#             logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n",
    "#             print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n",
    "#     except RuntimeError as e: # Memory growth must be set before GPUs have been initialized \n",
    "#         print(e) \n",
    "        \n",
    "def deserialize_example(serialized_string): \n",
    "    image_feature_description = { 'image': tf.io.FixedLenFeature([], tf.string), \n",
    "                                 'label': tf.io.FixedLenFeature([], tf.string), } \n",
    "    example = tf.io.parse_single_example(serialized_string, image_feature_description) \n",
    "    image = tf.reshape(tf.io.decode_raw(example[\"image\"], tf.float32), (32, 32, 3)) \n",
    "    label = tf.io.decode_raw(example[\"label\"], tf.float32) \n",
    "    \n",
    "    return image, label \n",
    "\n",
    "def conv_bn_relu(inputs, chs): \n",
    "    x = layers.Conv2D(chs, 3, padding=\"same\")(inputs) \n",
    "    x = layers.BatchNormalization()(x) \n",
    "    \n",
    "    return layers.ReLU()(x) \n",
    "\n",
    "def create_model(): \n",
    "    inputs = layers.Input((32, 32, 3)) \n",
    "    x = inputs \n",
    "    for chs in [64, 128, 256]: \n",
    "        for i in range(3): \n",
    "            x = conv_bn_relu(x, chs) \n",
    "        x = layers.AveragePooling2D(2)(x) \n",
    "    x = layers.GlobalAveragePooling2D()(x) \n",
    "    x = layers.Dense(10, activation=\"softmax\")(x) \n",
    "    return tf.keras.models.Model(inputs, x) \n",
    "\n",
    "def main(): \n",
    "    trainset = tf.data.TFRecordDataset(\"train.tfrecord\").map(deserialize_example).shuffle(2048).repeat().batch(128) \n",
    "    testset = tf.data.TFRecordDataset(\"test.tfrecord\").map(deserialize_example).batch(128) \n",
    "    model = create_model() \n",
    "    model.compile(\"adam\", \"categorical_crossentropy\", [\"accuracy\"]) \n",
    "    model.fit(trainset, steps_per_epoch=50000//128, validation_data=testset, epochs=3) \n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97933ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
