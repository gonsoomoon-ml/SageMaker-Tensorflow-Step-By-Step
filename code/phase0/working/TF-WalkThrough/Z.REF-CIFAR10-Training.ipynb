{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e1838f",
   "metadata": {},
   "source": [
    "# Cifar10: TF Custom training: walkthrough\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c7a38",
   "metadata": {},
   "source": [
    "# 0. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d3e2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow-gpu==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c202e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99f5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[7], 'GPU')\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e96bf",
   "metadata": {},
   "source": [
    "# 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "243b5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_DATA_BATCHES = 5\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000 * NUM_DATA_BATCHES\n",
    "INPUT_TENSOR_NAME = 'inputs_input'  # needs to match the name of the first layer + \"_input\"\n",
    "\n",
    "\n",
    "\n",
    "def get_filenames(channel_name, channel):\n",
    "    if channel_name in ['train', 'validation', 'eval']:\n",
    "        return [os.path.join(channel, channel_name + '.tfrecords')]\n",
    "    else:\n",
    "        raise ValueError('Invalid data subset \"%s\"' % channel_name)\n",
    "\n",
    "def _input(epochs, batch_size, channel, channel_name):\n",
    "\n",
    "    print(f\"\\nChannel Name: {channel_name}\\n\")     \n",
    "    filenames = get_filenames(channel_name, channel)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    #dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=3)\n",
    "\n",
    "    ds_size = sum(1 for _ in dataset)    \n",
    "    # print(\"# of batches loading TFRecord : {0}\".format(tf.data.experimental.cardinality(dataset).numpy()))    \n",
    "    print(\"# of batches loading TFRecord : {0}\".format(ds_size)) \n",
    "    # Parse records.\n",
    "    dataset = dataset.map(_dataset_parser, num_parallel_calls=10)\n",
    "\n",
    "    dataset = dataset.repeat(1)    \n",
    "    \n",
    "    # Potentially shuffle records.\n",
    "    if channel_name == 'train':\n",
    "        # Ensure that the capacity is sufficiently large to provide good random\n",
    "        # shuffling.\n",
    "        # buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\n",
    "        buffer_size = ds_size\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    " \n",
    "        print(\"buffer_size: \", buffer_size)\n",
    "    \n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _train_preprocess_fn(image):\n",
    "    \"\"\"Preprocess a single training image of layout [height, width, depth].\"\"\"\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.image.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def _dataset_parser(value):\n",
    "    \"\"\"Parse a CIFAR-10 record from value.\"\"\"\n",
    "    featdef = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(value, featdef)\n",
    "    image = tf.io.decode_raw(example['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "\n",
    "    image = _train_preprocess_fn(image)\n",
    "\n",
    "    return image, label    \n",
    "#    return image, tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "def save_model(model, output):\n",
    "    tf.saved_model.save(model, output+'/1/')\n",
    "    logging.info(\"Model successfully saved at: {}\".format(output))\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "770744d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../data/cifar10/train'\n",
    "validation_dir = '../../data/cifar10/validation'\n",
    "eval_dir = '../../data/cifar10/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86e872d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Name: train\n",
      "\n",
      "# of batches loading TFRecord : 40000\n",
      "buffer_size:  40000\n",
      "# of batches in train:  5000\n",
      "\n",
      "Channel Name: train\n",
      "\n",
      "# of batches loading TFRecord : 40000\n",
      "buffer_size:  40000\n",
      "# of batches in train:  5000\n",
      "\n",
      "Channel Name: train\n",
      "\n",
      "# of batches loading TFRecord : 40000\n",
      "buffer_size:  40000\n",
      "# of batches in train:  5000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = _input(5, 8, train_dir, 'train')\n",
    "train_batch_size = sum(1 for _ in train_dataset)    \n",
    "print(\"# of batches in train: \", train_batch_size)\n",
    "\n",
    "train_dataset2 = _input(5, 8, train_dir, 'train')\n",
    "train_batch_size = sum(1 for _ in train_dataset2)    \n",
    "print(\"# of batches in train: \", train_batch_size)\n",
    "\n",
    "train_dataset3 = _input(5, 8, train_dir, 'train')\n",
    "train_batch_size = sum(1 for _ in train_dataset3)    \n",
    "print(\"# of batches in train: \", train_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8673d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 8 9 3 6 9 7 0]\n",
      "[1 1 8 6 4 1 7 2]\n",
      "[2 9 2 2 9 5 4 2]\n"
     ]
    }
   ],
   "source": [
    "batch_num = 1\n",
    "for images, labels in train_dataset.take(batch_num):\n",
    "    labels = labels.numpy()\n",
    "    print(labels)\n",
    "    # print(labels.numpy().mean())\n",
    "    break\n",
    "\n",
    "batch_num = 1\n",
    "for images, labels in train_dataset2.take(batch_num):\n",
    "    labels = labels.numpy()\n",
    "    print(labels)\n",
    "    # print(labels.numpy().mean())\n",
    "    break\n",
    "\n",
    "batch_num = 1\n",
    "for images, labels in train_dataset3.take(batch_num):\n",
    "    labels = labels.numpy()\n",
    "    print(labels)\n",
    "    # print(labels.numpy().mean())\n",
    "    break\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42b8b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Name: train\n",
      "\n",
      "# of batches loading TFRecord : 40000\n",
      "buffer_size:  40000\n",
      "# of batches in train:  156\n",
      "\n",
      "Channel Name: validation\n",
      "\n",
      "# of batches loading TFRecord : 10000\n",
      "# of batches in validation:  1\n",
      "\n",
      "Channel Name: eval\n",
      "\n",
      "# of batches loading TFRecord : 10000\n",
      "# of batches in eval:  1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = _input(5, 256, train_dir, 'train')\n",
    "train_batch_size = sum(1 for _ in train_dataset)    \n",
    "print(\"# of batches in train: \", train_batch_size)\n",
    "\n",
    "\n",
    "validation_dataset = _input(5, 10000, validation_dir, 'validation')\n",
    "validation_batch_size = sum(1 for _ in validation_dataset)    \n",
    "print(\"# of batches in validation: \", validation_batch_size)\n",
    "\n",
    "\n",
    "eval_dataset = _input(5, 10000, eval_dir, 'eval')\n",
    "eval_batch_size = sum(1 for _ in eval_dataset)    \n",
    "print(\"# of batches in eval: \", eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fdfd2",
   "metadata": {},
   "source": [
    "# 2. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3cdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, [3, 3], activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(64, [3, 3], activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707094a6",
   "metadata": {},
   "source": [
    "# 3. 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c47a18",
   "metadata": {},
   "source": [
    "## Gradient 생성 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e46046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be68313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "#test_accuracy = tf.keras.metrics.CategoricalCrossentropy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    print(\"t_loss: \", t_loss)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82cdc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step2(test_loss,test_accuracy, images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    print(\"t_loss: \", t_loss)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac812fe0",
   "metadata": {},
   "source": [
    "# 4. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49064a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #0\tLoss: 1.730120\n",
      "t_loss:  Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Epoch 1, Test Loss: 1.7549176216125488, Test Accuracy: 36.869998931884766\n",
      "Step #0\tLoss: 1.836365\n",
      "Epoch 2, Test Loss: 1.6288703680038452, Test Accuracy: 40.88999938964844\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "print_interval = 200\n",
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch, (images, labels) in enumerate(train_dataset):\n",
    "        loss_value = train_step(images, labels)\n",
    "        \n",
    "        if batch % print_interval == 0:\n",
    "            print(\"Step #%d\\tLoss: %.6f\" %  (batch, loss_value))\n",
    "        \n",
    "        \n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "        \n",
    "\n",
    "    for test_images, test_labels in validation_dataset:\n",
    "#         test_step(test_images, test_labels)\n",
    "        test_step2(test_loss, test_accuracy, test_images, test_labels)        \n",
    "\n",
    "\n",
    "    template = 'Epoch {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))\n",
    "\n",
    "\n",
    "print('Training Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11507",
   "metadata": {},
   "source": [
    "# 5. 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3196d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Test Loss: 1.22633695602417, Test Accuracy: 56.849998474121094\n"
     ]
    }
   ],
   "source": [
    "# Reset the metrics at the start of the next epoch\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "n_batch = 10\n",
    "\n",
    "#for batch_id, (test_images, test_labels) in enumerate(validation_dataset.take(n_batch)):\n",
    "for batch_id, (test_images, test_labels) in enumerate(eval_dataset):\n",
    "    print(batch_id)\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "    print(\n",
    "    #ㅁ    f'Epoch {epoch + 1}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a735d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76441a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
