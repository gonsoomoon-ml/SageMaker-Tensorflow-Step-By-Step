{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.1] 세이지 메이커 로컬 모드 및 스크립트 모드로 훈련\n",
    "\n",
    "본 워크샵의 모든 노트북은 **<font color=\"red\">conda_tensorflow2_p36</font>** 를 사용합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- 1. 기본 환경 세팅 \n",
    "- 2. 노트북에서 세이지 메이커 스크립트 모드 스타일로 코드 변경\n",
    "- 3. 세이지 메이커 로컬 모드로 훈련\n",
    "- 4. 세이지 메이커의 호스트 모드로 훈련\n",
    "- 5. 모델 아티펙트 경로 저장\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기본 환경 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-cnn-cifar10\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_dir\n",
    "%store -r validation_dir\n",
    "%store -r eval_dir\n",
    "%store -r data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 노트북에서 세이지 메이커 스크립트 모드 스타일로 코드 변경\n",
    "\n",
    "- Keras 버전의 스크래치 코드에서 세이지 메이커의 코드 변경을 참고 하세요.\n",
    "    - `1.2.Train_Keras_Local_Script_Mode.ipynb` 참고\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize src/cifar10_tf2_sm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 세이지 메이커 로컬 모드로 훈련\n",
    "\n",
    "본격적으로 학습을 시작하기 전에 로컬 모드를 사용하여 디버깅을 먼저 수행합니다. 로컬 모드는 학습 인스턴스를 생성하는 과정이 없이 로컬 인스턴스로 컨테이너를 가져온 후 곧바로 학습을 수행하기 때문에 코드를 보다 신속히 검증할 수 있습니다.\n",
    "\n",
    "Amazon SageMaker Python SDK의 로컬 모드는 TensorFlow 또는 MXNet estimator서 단일 인자값을 변경하여 CPU (단일 및 다중 인스턴스) 및 GPU (단일 인스턴스) SageMaker 학습 작업을 에뮬레이션(enumlate)할 수 있습니다. \n",
    "\n",
    "로컬 모드 학습을 위해서는 docker-compose 또는 nvidia-docker-compose (GPU 인스턴스인 경우)의 설치가 필요합니다. 아래 코드 셀을 통해 본 노트북 환경에 docker-compose 또는 nvidia-docker-compose를 설치하고 구성합니다. \n",
    " \n",
    "로컬 모드의 학습을 통해 여러분의 코드가 현재 사용 중인 하드웨어를 적절히 활용하고 있는지 확인하기 위한 GPU 점유와 같은 지표(metric)를 쉽게 모니터링할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬 모드로 훈련 실행\n",
    "- 아래의 두 라인이 로컬모드로 훈련을 지시 합니다.\n",
    "```python\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "instance_type = \"local_gpu\" # GPU 사용을 가정 합니다. CPU 사용시에 'local' 로 정의 합니다.\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 작업을 시작하기 위해 `estimator.fit() ` 호출 시, Amazon ECS에서 Amazon SageMaker TensorFlow 컨테이너를 로컬 노트북 인스턴스로 다운로드합니다.\n",
    "\n",
    "`sagemaker.tensorflow` 클래스를 사용하여 SageMaker Python SDK의 Tensorflow Estimator 인스턴스를 생성합니다.\n",
    "인자값으로 하이퍼파라메터와 다양한 설정들을 변경할 수 있습니다.\n",
    "\n",
    "\n",
    "자세한 내용은 [documentation](https://sagemaker.readthedocs.io/en/stable/using_tf.html#training-with-tensorflow-estimator)을 확인하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "                    'epochs' : 1,\n",
    "                    'learning-rate' : 0.001,\n",
    "                    'print-interval' : 100,\n",
    "                    'train-batch-size': 256,    \n",
    "                    'eval-batch-size': 512,        \n",
    "                    'validation-batch-size': 512,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_tf2_sm.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       framework_version='2.4.1',\n",
    "                       py_version='py37',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters= hyperparameters,\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type= instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 6syhdngngx-algo-1-cl7gh ... \n",
      "Creating 6syhdngngx-algo-1-cl7gh ... done\n",
      "Attaching to 6syhdngngx-algo-1-cl7gh\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:53.710766: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:53.710971: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:53.715651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:53.754759: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:55,531 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:55,897 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Training Env:\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"eval\": \"/opt/ml/input/data/eval\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"current_host\": \"algo-1-cl7gh\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"algo-1-cl7gh\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     ],\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"learning-rate\": 0.001,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"print-interval\": 100,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"train-batch-size\": 256,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"eval-batch-size\": 512,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"validation-batch-size\": 512,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"train\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"validation\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"eval\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         }\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"job_name\": \"cifar10-2021-10-11-11-21-50-789\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"master_hostname\": \"algo-1-cl7gh\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/source/sourcedir.tar.gz\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"module_name\": \"cifar10_tf2_sm\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"num_gpus\": 1,\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"current_host\": \"algo-1-cl7gh\",\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m             \"algo-1-cl7gh\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m         ]\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     },\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m     \"user_entry_point\": \"cifar10_tf2_sm.py\"\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m }\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Environment variables:\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HOSTS=[\"algo-1-cl7gh\"]\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HPS={\"epochs\":1,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512}\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_USER_ENTRY_POINT=cifar10_tf2_sm.py\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-cl7gh\",\"hosts\":[\"algo-1-cl7gh\"]}\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_INPUT_DATA_CONFIG={\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_CHANNELS=[\"eval\",\"train\",\"validation\"]\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_CURRENT_HOST=algo-1-cl7gh\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_MODULE_NAME=cifar10_tf2_sm\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_NUM_GPUS=1\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/source/sourcedir.tar.gz\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-cl7gh\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-cl7gh\"],\"hyperparameters\":{\"epochs\":1,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-2021-10-11-11-21-50-789\",\"log_level\":20,\"master_hostname\":\"algo-1-cl7gh\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_tf2_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-cl7gh\",\"hosts\":[\"algo-1-cl7gh\"]},\"user_entry_point\":\"cifar10_tf2_sm.py\"}\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\",\"--eval-batch-size\",\"512\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model\",\"--print-interval\",\"100\",\"--train-batch-size\",\"256\",\"--validation-batch-size\",\"512\"]\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_CHANNEL_EVAL=/opt/ml/input/data/eval\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_LEARNING-RATE=0.001\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_PRINT-INTERVAL=100\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_TRAIN-BATCH-SIZE=256\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_EVAL-BATCH-SIZE=512\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_VALIDATION-BATCH-SIZE=512\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m /usr/local/bin/python3.7 cifar10_tf2_sm.py --epochs 1 --eval-batch-size 512 --learning-rate 0.001 --model_dir s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model --print-interval 100 --train-batch-size 256 --validation-batch-size 512\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m tensorflow version:  2.4.1\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m args: \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m  Namespace(epochs=1, eval='/opt/ml/input/data/eval', eval_batch_size=512, learning_rate=0.001, model_dir='s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-21-50-789/model', model_output_dir='/opt/ml/model', momentum=0.9, optimizer='adam', print_interval=100, train='/opt/ml/input/data/train', train_batch_size=256, validation='/opt/ml/input/data/validation', validation_batch_size=512, weight_decay=0.0002)\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Channel Name: train\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m buffer_size:  10000\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches in train:  39\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Channel Name: eval\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches in eval:  19\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Channel Name: validation\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches loading TFRecord : 10000\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m # of batches in validation:  19\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m [2021-10-11 11:22:05.203 6f19020ebdc1:37 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m [2021-10-11 11:22:05.237 6f19020ebdc1:37 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Step #0\tLoss: 60.272499\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Epoch 1, Test Loss: 2.293747663497925, Test Accuracy: 11.307565689086914\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m Training Finished.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:56.049740: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:56.049902: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:21:56.090474: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:22:09.289920: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m \n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh |\u001b[0m 2021-10-11 11:22:10,920 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36m6syhdngngx-algo-1-cl7gh exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "CPU times: user 601 ms, sys: 58.5 ms, total: 659 ms\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator.fit({'train': f'file://{train_dir}',\n",
    "               'validation': f'file://{validation_dir}',\n",
    "               'eval': f'file://{eval_dir}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 세이지 메이커의 호스트 모드로 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트를 S3에 업로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-227612457811/data/DEMO-cifar10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path=data_dir, key_prefix='data/DEMO-cifar10')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "                    'epochs' : 20,\n",
    "                    'learning-rate' : 0.001,    \n",
    "                    'print-interval' : 100,\n",
    "                    'train-batch-size': 256,    \n",
    "                    'eval-batch-size': 512,        \n",
    "                    'validation-batch-size': 512,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "instance_type='ml.p3.8xlarge'\n",
    "\n",
    "sm_estimator = TensorFlow(base_job_name='cifar10',\n",
    "                       entry_point='cifar10_tf2_sm.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       framework_version='2.4.1',\n",
    "                       py_version='py37',\n",
    "                       script_mode=True,\n",
    "                       hyperparameters= hyperparameters,\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type= instance_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Host Mode 로 훈련\n",
    "- `cifar10_estimator.fit(inputs, wait=False)`\n",
    "    - 입력 데이터를 inputs로서 S3 의 경로를 제공합니다.\n",
    "    - wait=False 로 지정해서 async 모드로 훈련을 실행합니다. \n",
    "        - 실행 경과는 아래의 cifar10_estimator.logs() 에서 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 267 ms, sys: 0 ns, total: 267 ms\n",
      "Wall time: 662 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-11 11:22:25 Starting - Starting the training job...\n",
      "2021-10-11 11:22:48 Starting - Launching requested ML instancesProfilerReport-1633951344: InProgress\n",
      "...\n",
      "2021-10-11 11:23:08 Starting - Insufficient capacity error from EC2 while launching instances, retrying!...........................\n",
      "2021-10-11 11:27:50 Starting - Preparing the instances for training.........\n",
      "2021-10-11 11:29:26 Downloading - Downloading input data\n",
      "2021-10-11 11:29:26 Training - Downloading the training image.................\u001b[34m2021-10-11 11:32:03.614371: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:03.627367: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:03.911369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:04.152537: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\n",
      "2021-10-11 11:32:11 Training - Training image download completed. Training in progress.\u001b[34m2021-10-11 11:32:14,661 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:15,477 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"validation-batch-size\": 512,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"print-interval\": 100,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model\",\n",
      "        \"train-batch-size\": 256,\n",
      "        \"epochs\": 20,\n",
      "        \"eval-batch-size\": 512\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-2021-10-11-11-22-24-452\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_tf2_sm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_tf2_sm.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10_tf2_sm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10_tf2_sm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"eval-batch-size\":512,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model\",\"print-interval\":100,\"train-batch-size\":256,\"validation-batch-size\":512},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-2021-10-11-11-22-24-452\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_tf2_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_tf2_sm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--eval-batch-size\",\"512\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model\",\"--print-interval\",\"100\",\"--train-batch-size\",\"256\",\"--validation-batch-size\",\"512\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION-BATCH-SIZE=512\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_PRINT-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL-BATCH-SIZE=512\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 cifar10_tf2_sm.py --epochs 20 --eval-batch-size 512 --learning-rate 0.001 --model_dir s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model --print-interval 100 --train-batch-size 256 --validation-batch-size 512\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mtensorflow version:  2.4.1\u001b[0m\n",
      "\u001b[34margs: \n",
      " Namespace(epochs=20, eval='/opt/ml/input/data/eval', eval_batch_size=512, learning_rate=0.001, model_dir='s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/model', model_output_dir='/opt/ml/model', momentum=0.9, optimizer='adam', print_interval=100, train='/opt/ml/input/data/train', train_batch_size=256, validation='/opt/ml/input/data/validation', validation_batch_size=512, weight_decay=0.0002)\n",
      "\u001b[0m\n",
      "\u001b[34mChannel Name: train\n",
      "\u001b[0m\n",
      "\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34mbuffer_size:  10000\u001b[0m\n",
      "\u001b[34m# of batches in train:  39\n",
      "\u001b[0m\n",
      "\u001b[34mChannel Name: eval\n",
      "\u001b[0m\n",
      "\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34m# of batches in eval:  19\n",
      "\u001b[0m\n",
      "\u001b[34mChannel Name: validation\n",
      "\u001b[0m\n",
      "\u001b[34m# of batches loading TFRecord : 10000\u001b[0m\n",
      "\u001b[34m# of batches in validation:  19\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.367 ip-10-0-217-253.ec2.internal:82 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.524 ip-10-0-217-253.ec2.internal:82 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.526 ip-10-0-217-253.ec2.internal:82 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.526 ip-10-0-217-253.ec2.internal:82 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.527 ip-10-0-217-253.ec2.internal:82 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.527 ip-10-0-217-253.ec2.internal:82 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-10-11 11:32:30.527 ip-10-0-217-253.ec2.internal:82 INFO hook.py:413] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 54.056965\u001b[0m\n",
      "\u001b[34mEpoch 1, Test Loss: 2.26065731048584, Test Accuracy: 14.597039222717285\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 2.259690\u001b[0m\n",
      "\u001b[34mEpoch 2, Test Loss: 2.19937801361084, Test Accuracy: 18.359375\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 2.182891\u001b[0m\n",
      "\u001b[34mEpoch 3, Test Loss: 2.1109817028045654, Test Accuracy: 23.273027420043945\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 2.147202\u001b[0m\n",
      "\u001b[34mEpoch 4, Test Loss: 1.8995871543884277, Test Accuracy: 30.345396041870117\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.824833\u001b[0m\n",
      "\u001b[34mEpoch 5, Test Loss: 1.8044137954711914, Test Accuracy: 33.72738265991211\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.833963\u001b[0m\n",
      "\u001b[34mEpoch 6, Test Loss: 1.774757742881775, Test Accuracy: 35.99917984008789\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.647774\u001b[0m\n",
      "\u001b[34mEpoch 7, Test Loss: 1.7256040573120117, Test Accuracy: 37.67475128173828\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.783340\u001b[0m\n",
      "\u001b[34mEpoch 8, Test Loss: 1.6955578327178955, Test Accuracy: 38.558799743652344\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.576285\u001b[0m\n",
      "\u001b[34mEpoch 9, Test Loss: 1.6572834253311157, Test Accuracy: 40.00822448730469\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.645678\u001b[0m\n",
      "\u001b[34mEpoch 10, Test Loss: 1.670272707939148, Test Accuracy: 39.81291198730469\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.600603\u001b[0m\n",
      "\u001b[34mEpoch 11, Test Loss: 1.6322380304336548, Test Accuracy: 40.95394515991211\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.611182\u001b[0m\n",
      "\u001b[34mEpoch 12, Test Loss: 1.579511284828186, Test Accuracy: 43.68832015991211\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.509589\u001b[0m\n",
      "\u001b[34mEpoch 13, Test Loss: 1.5858755111694336, Test Accuracy: 42.93791198730469\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.572258\u001b[0m\n",
      "\u001b[34mEpoch 14, Test Loss: 1.5317524671554565, Test Accuracy: 44.7265625\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.436440\u001b[0m\n",
      "\u001b[34mEpoch 15, Test Loss: 1.586836576461792, Test Accuracy: 43.32853698730469\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.452503\u001b[0m\n",
      "\u001b[34mEpoch 16, Test Loss: 1.5158073902130127, Test Accuracy: 45.970394134521484\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.388567\u001b[0m\n",
      "\u001b[34mEpoch 17, Test Loss: 1.4940433502197266, Test Accuracy: 46.607730865478516\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.399346\u001b[0m\n",
      "\u001b[34mEpoch 18, Test Loss: 1.5035525560379028, Test Accuracy: 46.65912628173828\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.477137\u001b[0m\n",
      "\u001b[34mEpoch 19, Test Loss: 1.4569551944732666, Test Accuracy: 48.61225128173828\u001b[0m\n",
      "\u001b[34mStep #0#011Loss: 1.421552\u001b[0m\n",
      "\u001b[34mEpoch 20, Test Loss: 1.4467573165893555, Test Accuracy: 48.76644515991211\u001b[0m\n",
      "\u001b[34mTraining Finished.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:15.626970: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:15.627125: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:32:15.669046: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-10-11 11:33:01.658410: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "\u001b[0m\n",
      "\u001b[34m2021-10-11 11:33:04,626 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-10-11 11:33:31 Uploading - Uploading generated training model\n",
      "2021-10-11 11:33:31 Completed - Training job completed\n",
      "ProfilerReport-1633951344: NoIssuesFound\n",
      "Training seconds: 258\n",
      "Billable seconds: 258\n"
     ]
    }
   ],
   "source": [
    "sm_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 아티펙트 저장\n",
    "- S3 에 저장된 모델 아티펙트를 저장하여 추론시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_tf_artifact_path:  s3://sagemaker-us-east-1-227612457811/cifar10-2021-10-11-11-22-24-452/output/model.tar.gz\n",
      "Stored 'tf2_script_artifact_path' (str)\n"
     ]
    }
   ],
   "source": [
    "tf2_script_artifact_path = sm_estimator.model_data\n",
    "print(\"script_tf_artifact_path: \", tf2_script_artifact_path)\n",
    "\n",
    "%store tf2_script_artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
